{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.append('../parsing_and_plotting/')\n",
    "from parse_data import * \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 9000)\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Typing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make function for conversion, to be used in this run of the notebook:\n",
    "p_group_dict = make_p_group_dict()\n",
    "e_group_dict = make_e_group_dict()\n",
    "\n",
    "def convert_allele(allele, resolution = 'two_field'):\n",
    "\n",
    "    \"\"\"\n",
    "    input:\n",
    "    allele (str): An allele in the format (A|B|C|DRB1|DQB1)\\*\\d{2}:\\d{2,3}:?\\d{0,3}G?:?\\d{0,3} to be converted.\n",
    "    resolution:   the resolution, with which the allele is converted to\n",
    "\n",
    "    \"\"\"\n",
    "    if resolution == \"one_field\":\n",
    "        converted_allele = convert_to_one_field(allele)\n",
    "    \n",
    "    elif resolution == \"two_field\":\n",
    "        converted_allele = convert_to_two_field(allele)\n",
    "        \n",
    "    elif resolution == \"p_group\":\n",
    "        converted_allele = convert_to_p_group(allele, p_group_dict=p_group_dict)\n",
    "    \n",
    "    elif resolution == \"e_group\":\n",
    "        converted_allele = convert_to_e_group(allele, e_group_dict=e_group_dict, p_group_dict=p_group_dict)\n",
    "            \n",
    "    else:\n",
    "        print(\"A conversion mistake happend. Please specify a correct conversion type.\")\n",
    "        converted_allele = None\n",
    "        \n",
    "    return converted_allele      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_resultpath(read_length='65', coverage='50', damage='no_dmg'):\n",
    "    if damage == 'dmg':\n",
    "        resultpath = f'results/damaged_reads/{read_length}_read_length/{coverage}X_coverage/'\n",
    "    else:\n",
    "        resultpath = f'results/no_damage/{read_length}_read_length/{coverage}X_coverage/'\n",
    "\n",
    "    return resultpath\n",
    "\n",
    "def load_optitype_results(optitype_result_filepath):\n",
    "\n",
    "    optitype_files = []\n",
    "    for (dirpath, dirnames, filenames) in walk(optitype_result_filepath):\n",
    "        optitype_files.extend(filenames)\n",
    "\n",
    "    #print(optitype_files)\n",
    "\n",
    "    optitype_results = dict()\n",
    "\n",
    "    for filename in optitype_files:\n",
    "\n",
    "        #Check for right file, and that the file is not empty\n",
    "        if (filename.endswith('.tsv')) and (os.stat(optitype_result_filepath + filename).st_size != 0):\n",
    "            temp_results_raw = list(pd.read_csv(optitype_result_filepath + filename, sep = \"\\t\").iloc[0])[1:7]\n",
    "\n",
    "            temp_results = [i for i in temp_results_raw if isinstance(i,str)]\n",
    "\n",
    "            #Make dict of dicts for results:\n",
    "            temp_result_dict = dict()\n",
    "\n",
    "            for pred in temp_results:\n",
    "                gene = re.search(r\"(A|B|C|DRB1|DQB1)\", pred).group(0)\n",
    "\n",
    "                pred_converted = convert_allele(pred)\n",
    "\n",
    "                #Add to list of predictions for this sample\n",
    "                if gene not in temp_result_dict.keys():\n",
    "                    temp_result_dict[gene] = [[pred_converted]]\n",
    "                else:\n",
    "                    temp_result_dict[gene] += [[pred_converted]]\n",
    "\n",
    "            optitype_results[filename[:-11]] = temp_result_dict\n",
    "\n",
    "        #Add empty entry for empty file\n",
    "        elif (filename.endswith('.tsv')) and (os.stat(optitype_result_filepath + filename).st_size == 0):\n",
    "            optitype_results[filename[:-11]] = dict()\n",
    "\n",
    "    return optitype_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optitype_typing_dict = dict()\n",
    "\n",
    "# read_lengths = [\"13\", \"15\", '20', '25','30','35', '45', '55', '65']\n",
    "# coverages = ['1', '2','5', '10', '20', \"50\"]\n",
    "\n",
    "# for dmg in ['dmg', 'no_dmg']:\n",
    "#     optitype_typing_dict[dmg] = dict()\n",
    "#     for rl in read_lengths:\n",
    "#         optitype_typing_dict[dmg][rl] = dict()\n",
    "#         for cov in coverages:\n",
    "#             optitype_typing_dict[dmg][rl][cov] = load_optitype_results(define_resultpath(read_length=rl, coverage=cov, damage=dmg))\n",
    "\n",
    "# with open('results/optitype_typing_dict.json', 'w') as outfile:\n",
    "#     json.dump(optitype_typing_dict, outfile)\n",
    "\n",
    "with open('results/optitype_typing_dict.json', 'r') as infile:\n",
    "    optitype_typing_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Gold standard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MG_exome_merged_df = pd.read_pickle(\"../parsing_and_plotting/result_data/MG_exome_merged_df.pkl\")\n",
    "\n",
    "gs_two_field_df = pd.read_pickle(\"../parsing_and_plotting/result_data/gs_two_field_df.pkl\")\n",
    "\n",
    "#Only pick the samples included in the aDNA study\n",
    "with open(\"config.yaml\", \"r\") as stream:\n",
    "    config_dict = yaml.safe_load(stream)\n",
    "\n",
    "gold_standard_id_list = config_dict['sample_id']\n",
    "\n",
    "gs_two_field_df = gs_two_field_df.loc[gold_standard_id_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Results - Typing Accuracy + Call Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_call(correct_alleles, predicted_alleles, resolution):\n",
    "    #Start by converting the alleles to the correct resolution\n",
    "    correct_call_1 = {convert_allele(allele, resolution=resolution) for allele in correct_alleles[0]}\n",
    "    correct_call_2 = {convert_allele(allele, resolution=resolution) for allele in correct_alleles[1]}\n",
    "\n",
    "    pred_1 = {convert_allele(predicted_alleles[0][0], resolution=resolution)}\n",
    "    pred_2 = {convert_allele(predicted_alleles[1][0], resolution=resolution)}\n",
    "\n",
    "    try:\n",
    "        correct_0_pred_0 = list(correct_call_1.intersection(pred_1))\n",
    "        correct_1_pred_1  = list(correct_call_2.intersection(pred_2))\n",
    "\n",
    "        option_1 = [correct_0_pred_0, correct_1_pred_1]\n",
    "\n",
    "        correct_0_pred_1  = list(correct_call_1.intersection(pred_2))\n",
    "        correct_1_pred_0  = list(correct_call_2.intersection(pred_1))\n",
    "\n",
    "        option_2 = [correct_0_pred_1, correct_1_pred_0]\n",
    "\n",
    "        hits_1 = len([i for i in option_1 if i != []])\n",
    "        hits_2 = len([i for i in option_2 if i != []])\n",
    "\n",
    "        num_correct_hits = max(hits_1,hits_2)\n",
    "        \n",
    "        \n",
    "    except KeyError as error:\n",
    "        num_correct_hits = 0\n",
    "    \n",
    "    return num_correct_hits\n",
    "\n",
    "#Get the number of predictions from a tool for a specific allele for a specific subject (2 or 0)\n",
    "def get_count(tool_prediction):\n",
    "    try:\n",
    "        pred = tool_prediction\n",
    "        return len(pred)\n",
    "    except KeyError as error:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_typing(optitype_typing_dict, gold_standard_df, resolution):\n",
    "    loci = ['A', 'B', 'C']\n",
    "    results_dict = dict()\n",
    "    total_correct_calls = 2 * len(gold_standard_id_list)\n",
    "\n",
    "\n",
    "    #Loop over parameters\n",
    "    for dmg, read_length_dict in optitype_typing_dict.items():\n",
    "        results_dict[dmg] = dict()\n",
    "        for rl, coverage_dict in read_length_dict.items():\n",
    "            results_dict[dmg][rl] = dict()\n",
    "            for cov,_ in coverage_dict.items():\n",
    "                results_dict[dmg][rl][cov] = dict()\n",
    "                for locus in loci:\n",
    "                    results_dict[dmg][rl][cov][locus] = dict()\n",
    "                    results_dict[dmg][rl][cov][locus]['count'] = 0\n",
    "                    results_dict[dmg][rl][cov][locus]['score'] = 0\n",
    "                    \n",
    "                    #Only include combinations, where all samples had high enough coverage - even when read length was low.\n",
    "                    for subject in gold_standard_df.index:\n",
    "                        #If typing exists:\n",
    "                        if subject in optitype_typing_dict[dmg][rl][cov]:\n",
    "                            if locus in optitype_typing_dict[dmg][rl][cov][subject]:\n",
    "                                optitype_pred = optitype_typing_dict[dmg][rl][cov][subject][locus]\n",
    "                                #Count number of total calls:\n",
    "                                results_dict[dmg][rl][cov][locus]['count'] += len(optitype_pred)\n",
    "                            \n",
    "                                #check whether it is valid.\n",
    "                                correct_alleles_list = gold_standard_df.loc[subject, locus]\n",
    "                                predicted_alleles = optitype_typing_dict[dmg][rl][cov][subject][locus]\n",
    "                                results_dict[dmg][rl][cov][locus]['score'] += validate_call(correct_alleles_list, optitype_pred, resolution)\n",
    "\n",
    "                                \n",
    "                    results_dict[dmg][rl][cov][locus]['call_rate'] = results_dict[dmg][rl][cov][locus]['count'] * 100  / total_correct_calls\n",
    "                    results_dict[dmg][rl][cov][locus]['typing_accuracy'] = results_dict[dmg][rl][cov][locus]['score'] * 100 / total_correct_calls\n",
    "\n",
    "                #Calculate across all class I\n",
    "                results_dict[dmg][rl][cov]['HLA-I'] = dict()\n",
    "                results_dict[dmg][rl][cov]['HLA-I']['count'] = sum([results_dict[dmg][rl][cov][locus]['count'] for locus in loci]) \n",
    "                results_dict[dmg][rl][cov]['HLA-I']['score'] = sum([results_dict[dmg][rl][cov][locus]['score'] for locus in loci]) \n",
    "\n",
    "                results_dict[dmg][rl][cov]['HLA-I']['call_rate'] = results_dict[dmg][rl][cov]['HLA-I']['count'] * 100  / (3 * total_correct_calls)\n",
    "                results_dict[dmg][rl][cov]['HLA-I']['typing_accuracy'] = results_dict[dmg][rl][cov]['HLA-I']['score'] * 100 / (3 * total_correct_calls)\n",
    "\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "\n",
    "for resolution in ['one_field', 'two_field', 'p_group', 'e_group']:\n",
    "    results_dict[resolution] = validate_typing(optitype_typing_dict, gold_standard_df=gs_two_field_df, resolution=resolution)\n",
    "\n",
    "\n",
    "with open(f'results/results_dict_aDNA_all_resolutions.json', 'w') as outfile:\n",
    "    json.dump(results_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
